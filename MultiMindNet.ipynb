{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Access Drive File**"
      ],
      "metadata": {
        "id": "0SaDjIvDHiK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0OGOURoHhEK",
        "outputId": "272e532e-f16d-443b-f9d7-728e079ad415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Behavioral Assessments Dataset**"
      ],
      "metadata": {
        "id": "yB6H_KrzCRa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "j2A9DKWHHuSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text-to-Embeddings Conversion Using BERT**"
      ],
      "metadata": {
        "id": "bUcN1a6VIfJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# -----------------------------------\n",
        "# 0. Download NLTK stopwords\n",
        "# -----------------------------------\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Preprocessing function\n",
        "# -----------------------------------\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()  # lowercase\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # remove unwanted chars\n",
        "    tokens = [word for word in text.split() if word not in stop_words]  # remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Load BERT model + tokenizer\n",
        "# -----------------------------------\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Embedding function (Eqns 3–6)\n",
        "# -----------------------------------\n",
        "def get_bert_embeddings(text, pooling=\"cls\"):\n",
        "    \"\"\"Convert text into embeddings using BERT\"\"\"\n",
        "    clean_text = preprocess_text(text)\n",
        "    inputs = tokenizer(clean_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    last_hidden_state = outputs.last_hidden_state.squeeze(0)  # (seq_len, hidden_dim)\n",
        "    cls_embedding = outputs.pooler_output.squeeze(0)          # CLS token embedding\n",
        "\n",
        "    if pooling == \"cls\":\n",
        "        return cls_embedding.numpy()\n",
        "    elif pooling == \"mean\":\n",
        "        return last_hidden_state.mean(dim=0).numpy()\n",
        "    else:\n",
        "        raise ValueError(\"Pooling must be 'cls' or 'mean'\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 4. Fusion with EEG embeddings (Eqn 7)\n",
        "# -----------------------------------\n",
        "def fuse_embeddings(eeg_embedding, text_embedding, w1=0.5, w2=0.5, bias=0.1):\n",
        "    eeg_part = w1 * np.array(eeg_embedding)\n",
        "    text_part = w2 * np.array(text_embedding) + bias\n",
        "    return np.concatenate([eeg_part, text_part])\n",
        "\n",
        "# -----------------------------------\n",
        "# 5. Process CSV input\n",
        "# -----------------------------------\n",
        "def process_csv(input_csv, text_column, output_csv, pooling=\"cls\", use_fusion=False, keep_columns=None):\n",
        "    \"\"\"\n",
        "    input_csv: path to input CSV file\n",
        "    text_column: name of the column containing text\n",
        "    output_csv: path to save embeddings + label column\n",
        "    pooling: 'cls' or 'mean'\n",
        "    use_fusion: whether to fuse with EEG embeddings\n",
        "    keep_columns: list of columns from the input CSV to also include in the output\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    embeddings = []\n",
        "    for idx, text in enumerate(df[text_column]):\n",
        "        emb = get_bert_embeddings(str(text), pooling=pooling)\n",
        "\n",
        "        if use_fusion:\n",
        "            eeg_emb = np.random.rand(len(emb))  # Simulated EEG embedding\n",
        "            emb = fuse_embeddings(eeg_emb, emb)\n",
        "\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    # Convert list of embeddings to DataFrame\n",
        "    emb_df = pd.DataFrame(embeddings)\n",
        "\n",
        "    # Add original column(s) back\n",
        "    if keep_columns is None:\n",
        "        emb_df[text_column] = df[text_column]\n",
        "    else:\n",
        "        for col in keep_columns:\n",
        "            emb_df[col] = df[col]\n",
        "\n",
        "    # Save to CSV\n",
        "    emb_df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Saved embeddings + labels to {output_csv}\")\n",
        "\n",
        "# -----------------------------------\n",
        "# Example usage\n",
        "# -----------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/Dataset-Mental-Disorders.csv\"\n",
        "    output_csv = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/text_embeddings.csv\"\n",
        "    text_column = \"Expert Diagnose\"   # column containing text\n",
        "\n",
        "    # Keep additional output columns (optional)\n",
        "    keep_cols = [\"Expert Diagnose\"]   # or e.g. [\"Expert Diagnose\", \"Patient ID\", \"Age\"]\n",
        "\n",
        "    # Process CSV → Save embeddings\n",
        "    process_csv(input_csv, text_column, output_csv, pooling=\"cls\", use_fusion=True, keep_columns=keep_cols)\n",
        "\n",
        "    # Load and check\n",
        "    df = pd.read_csv(output_csv)\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q6ciikAOPed",
        "outputId": "45c3963d-3a90-4f76-b4cd-c346b78459a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved embeddings + labels to /content/drive/MyDrive/Colab Notebooks/archive (22)/text_embeddings.csv\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0  0.163934  0.020747  0.053941  0.389782  0.453994  0.055306  0.424364   \n",
            "1  0.221380  0.264213  0.396977  0.465149  0.101821  0.118971  0.093329   \n",
            "2  0.409628  0.439373  0.326223  0.442865  0.024248  0.016242  0.158557   \n",
            "3  0.107815  0.043820  0.388044  0.189001  0.481159  0.419166  0.469136   \n",
            "4  0.339679  0.495903  0.433516  0.274738  0.421538  0.043065  0.020213   \n",
            "\n",
            "          7         8         9  ...      1527      1528      1529      1530  \\\n",
            "0  0.068270  0.478556  0.157259  ...  0.230639  0.217148  0.502674  0.181111   \n",
            "1  0.010445  0.181457  0.211408  ...  0.166952  0.390829  0.520842  0.036960   \n",
            "2  0.154312  0.349947  0.482482  ...  0.230639  0.217148  0.502674  0.181111   \n",
            "3  0.273275  0.336277  0.117473  ...  0.230639  0.217148  0.502674  0.181111   \n",
            "4  0.013070  0.137461  0.242913  ...  0.234224  0.376376  0.546580  0.080223   \n",
            "\n",
            "       1531      1532      1533      1534      1535  Expert Diagnose  \n",
            "0  0.270548  0.304391  0.211088 -0.176220  0.496421   Bipolar Type-2  \n",
            "1  0.255527  0.362594  0.108302 -0.231140  0.544519       Depression  \n",
            "2  0.270548  0.304391  0.211088 -0.176220  0.496421   Bipolar Type-1  \n",
            "3  0.270548  0.304391  0.211088 -0.176220  0.496421   Bipolar Type-2  \n",
            "4  0.337823  0.370450  0.159855 -0.191248  0.555832           Normal  \n",
            "\n",
            "[5 rows x 1537 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature extraction**"
      ],
      "metadata": {
        "id": "c7GGy_JHQlZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM-CNN Algorithm**"
      ],
      "metadata": {
        "id": "KkpK42DZSAgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Import Libraries\n",
        "# -----------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load CSV\n",
        "# -----------------------------\n",
        "csv_file = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/text_embeddings.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Separate features and labels\n",
        "y = df['Expert Diagnose'].values\n",
        "X = df.drop('Expert Diagnose', axis=1).values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Infer number of channels and time steps\n",
        "# -----------------------------\n",
        "num_channels = 14  # adjust for your EEG\n",
        "total_features = X.shape[1]\n",
        "\n",
        "if total_features % num_channels != 0:\n",
        "    time_steps = total_features // num_channels\n",
        "    X = X[:, :num_channels*time_steps]\n",
        "else:\n",
        "    time_steps = total_features // num_channels\n",
        "\n",
        "print(f\"Num channels: {num_channels}, Time steps: {time_steps}, X shape: {X.shape}\")\n",
        "\n",
        "X = X.reshape(-1, num_channels, time_steps)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. EEG Dataset Class\n",
        "# -----------------------------\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = EEGDataset(X, y_encoded)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. BiLSTM-CNN Model (Feature Extractor)\n",
        "# -----------------------------\n",
        "class BiLSTM_CNN_FeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_channels, time_steps, hidden_dim, cnn_out_channels):\n",
        "        super(BiLSTM_CNN_FeatureExtractor, self).__init__()\n",
        "\n",
        "        # BiLSTM\n",
        "        self.bilstm = nn.LSTM(input_size=input_channels, hidden_size=hidden_dim,\n",
        "                              num_layers=1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # CNN\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=cnn_out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # BiLSTM features\n",
        "        x_lstm = x.permute(0, 2, 1)  # (batch, time_steps, channels)\n",
        "        lstm_out, _ = self.bilstm(x_lstm)\n",
        "        lstm_feat = lstm_out[:, -1, :]  # last time step\n",
        "\n",
        "        # CNN features\n",
        "        cnn_out = self.conv1(x)\n",
        "        cnn_out = self.relu(cnn_out)\n",
        "        cnn_out = self.pool(cnn_out)\n",
        "        cnn_feat = cnn_out.view(cnn_out.size(0), -1)\n",
        "\n",
        "        # Concatenate features\n",
        "        fused_feat = torch.cat((lstm_feat, cnn_feat), dim=1)\n",
        "        return fused_feat\n",
        "\n",
        "hidden_dim = 64\n",
        "cnn_out_channels = 32\n",
        "model = BiLSTM_CNN_FeatureExtractor(input_channels=num_channels, time_steps=time_steps,\n",
        "                                    hidden_dim=hidden_dim, cnn_out_channels=cnn_out_channels)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Extract Features and Save to CSV\n",
        "# -----------------------------\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in loader:\n",
        "        feats = model(X_batch)\n",
        "        all_features.append(feats.numpy())\n",
        "        all_labels.append(y_batch.numpy())\n",
        "\n",
        "all_features = np.vstack(all_features)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Combine features and labels\n",
        "df_features = pd.DataFrame(all_features)\n",
        "df_features['Expert Diagnose'] = all_labels\n",
        "\n",
        "# Save to CSV\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/extraction_features.csv\"\n",
        "df_features.to_csv(output_csv, index=False)\n",
        "print(f\"Feature extraction completed. Saved to {output_csv}\")\n",
        "\n",
        "df_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "UG-61P-sPXJ6",
        "outputId": "b851eea2-acb3-45ca-840e-b5e048693be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num channels: 14, Time steps: 109, X shape: (120, 1526)\n",
            "Feature extraction completed. Saved to /content/drive/MyDrive/Colab Notebooks/archive (22)/extraction_features.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0   -0.023460 -0.009872  0.082980  0.052413  0.006048  0.141314  0.243438   \n",
              "1   -0.084386 -0.103192 -0.088962  0.030697 -0.028180  0.006336 -0.020375   \n",
              "2   -0.018671 -0.069374  0.078253 -0.088370  0.020094  0.086396  0.116505   \n",
              "3    0.027535 -0.089727  0.029530  0.006031  0.069494  0.010698  0.075243   \n",
              "4   -0.083207 -0.132342  0.056536 -0.014271 -0.072003  0.103119  0.138146   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "115 -0.112506 -0.043592 -0.112485  0.127277 -0.082939  0.006761  0.012738   \n",
              "116 -0.007931 -0.074937  0.070425  0.139553  0.022574  0.101328  0.171554   \n",
              "117 -0.017736 -0.104074 -0.039863  0.014642  0.042931  0.074098  0.047254   \n",
              "118 -0.050813  0.036072 -0.107408  0.139934 -0.081417  0.059574  0.057207   \n",
              "119 -0.039420 -0.141995  0.006620 -0.045237 -0.048196  0.079072  0.072306   \n",
              "\n",
              "            7         8         9  ...      1847      1848      1849  \\\n",
              "0   -0.079263  0.024943  0.031178  ...  0.171451  0.000000  0.315461   \n",
              "1   -0.022547  0.086264  0.062180  ...  0.564366  0.000000  0.719081   \n",
              "2   -0.109338  0.081247 -0.068201  ...  0.000000  0.675273  0.000000   \n",
              "3   -0.070218  0.108728 -0.032648  ...  0.892055  0.267894  0.000000   \n",
              "4   -0.020543 -0.044462 -0.131839  ...  0.831823  0.174909  0.318508   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "115  0.029169  0.015405  0.079715  ...  0.333294  0.429890  0.106210   \n",
              "116 -0.066366  0.055047  0.035051  ...  0.069739  0.000000  0.000000   \n",
              "117 -0.105637  0.084942 -0.068229  ...  0.310899  0.000000  0.292860   \n",
              "118  0.059609 -0.022578  0.099347  ...  0.000000  0.000000  0.240604   \n",
              "119 -0.027263 -0.056085 -0.108894  ...  0.195665  0.267506  0.455820   \n",
              "\n",
              "         1850      1851      1852      1853      1854      1855  \\\n",
              "0    0.000000  0.028471  0.535123  0.723172  0.000000  0.000000   \n",
              "1    0.366801  0.707353  0.582269  0.000000  0.654189  1.796574   \n",
              "2    0.044222  0.000000  0.000000  0.000000  0.258092  0.000000   \n",
              "3    0.573140  0.000000  0.000000  0.574548  0.065988  0.000000   \n",
              "4    0.000000  0.471079  0.000000  0.023926  0.197720  0.390639   \n",
              "..        ...       ...       ...       ...       ...       ...   \n",
              "115  0.365571  0.402822  0.287952  0.023290  0.104864  1.433301   \n",
              "116  0.886581  0.000000  0.000000  0.976803  0.156914  0.000000   \n",
              "117  0.218753  0.201924  0.000000  1.227339  0.220512  0.000000   \n",
              "118  0.552566  0.734320  0.365220  0.000000  0.425974  1.785931   \n",
              "119  0.000000  0.368746  0.000000  0.375127  0.027289  0.950704   \n",
              "\n",
              "     Expert Diagnose  \n",
              "0                  1  \n",
              "1                  2  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  3  \n",
              "..               ...  \n",
              "115                2  \n",
              "116                0  \n",
              "117                1  \n",
              "118                2  \n",
              "119                3  \n",
              "\n",
              "[120 rows x 1857 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32550921-4a04-4a48-92a0-90fe245d0e61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1847</th>\n",
              "      <th>1848</th>\n",
              "      <th>1849</th>\n",
              "      <th>1850</th>\n",
              "      <th>1851</th>\n",
              "      <th>1852</th>\n",
              "      <th>1853</th>\n",
              "      <th>1854</th>\n",
              "      <th>1855</th>\n",
              "      <th>Expert Diagnose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.023460</td>\n",
              "      <td>-0.009872</td>\n",
              "      <td>0.082980</td>\n",
              "      <td>0.052413</td>\n",
              "      <td>0.006048</td>\n",
              "      <td>0.141314</td>\n",
              "      <td>0.243438</td>\n",
              "      <td>-0.079263</td>\n",
              "      <td>0.024943</td>\n",
              "      <td>0.031178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.171451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028471</td>\n",
              "      <td>0.535123</td>\n",
              "      <td>0.723172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.084386</td>\n",
              "      <td>-0.103192</td>\n",
              "      <td>-0.088962</td>\n",
              "      <td>0.030697</td>\n",
              "      <td>-0.028180</td>\n",
              "      <td>0.006336</td>\n",
              "      <td>-0.020375</td>\n",
              "      <td>-0.022547</td>\n",
              "      <td>0.086264</td>\n",
              "      <td>0.062180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.564366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.719081</td>\n",
              "      <td>0.366801</td>\n",
              "      <td>0.707353</td>\n",
              "      <td>0.582269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.654189</td>\n",
              "      <td>1.796574</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.018671</td>\n",
              "      <td>-0.069374</td>\n",
              "      <td>0.078253</td>\n",
              "      <td>-0.088370</td>\n",
              "      <td>0.020094</td>\n",
              "      <td>0.086396</td>\n",
              "      <td>0.116505</td>\n",
              "      <td>-0.109338</td>\n",
              "      <td>0.081247</td>\n",
              "      <td>-0.068201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.675273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.027535</td>\n",
              "      <td>-0.089727</td>\n",
              "      <td>0.029530</td>\n",
              "      <td>0.006031</td>\n",
              "      <td>0.069494</td>\n",
              "      <td>0.010698</td>\n",
              "      <td>0.075243</td>\n",
              "      <td>-0.070218</td>\n",
              "      <td>0.108728</td>\n",
              "      <td>-0.032648</td>\n",
              "      <td>...</td>\n",
              "      <td>0.892055</td>\n",
              "      <td>0.267894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.573140</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.574548</td>\n",
              "      <td>0.065988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.083207</td>\n",
              "      <td>-0.132342</td>\n",
              "      <td>0.056536</td>\n",
              "      <td>-0.014271</td>\n",
              "      <td>-0.072003</td>\n",
              "      <td>0.103119</td>\n",
              "      <td>0.138146</td>\n",
              "      <td>-0.020543</td>\n",
              "      <td>-0.044462</td>\n",
              "      <td>-0.131839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.831823</td>\n",
              "      <td>0.174909</td>\n",
              "      <td>0.318508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471079</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023926</td>\n",
              "      <td>0.197720</td>\n",
              "      <td>0.390639</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>-0.112506</td>\n",
              "      <td>-0.043592</td>\n",
              "      <td>-0.112485</td>\n",
              "      <td>0.127277</td>\n",
              "      <td>-0.082939</td>\n",
              "      <td>0.006761</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.029169</td>\n",
              "      <td>0.015405</td>\n",
              "      <td>0.079715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333294</td>\n",
              "      <td>0.429890</td>\n",
              "      <td>0.106210</td>\n",
              "      <td>0.365571</td>\n",
              "      <td>0.402822</td>\n",
              "      <td>0.287952</td>\n",
              "      <td>0.023290</td>\n",
              "      <td>0.104864</td>\n",
              "      <td>1.433301</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>-0.007931</td>\n",
              "      <td>-0.074937</td>\n",
              "      <td>0.070425</td>\n",
              "      <td>0.139553</td>\n",
              "      <td>0.022574</td>\n",
              "      <td>0.101328</td>\n",
              "      <td>0.171554</td>\n",
              "      <td>-0.066366</td>\n",
              "      <td>0.055047</td>\n",
              "      <td>0.035051</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.886581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.976803</td>\n",
              "      <td>0.156914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>-0.017736</td>\n",
              "      <td>-0.104074</td>\n",
              "      <td>-0.039863</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>0.042931</td>\n",
              "      <td>0.074098</td>\n",
              "      <td>0.047254</td>\n",
              "      <td>-0.105637</td>\n",
              "      <td>0.084942</td>\n",
              "      <td>-0.068229</td>\n",
              "      <td>...</td>\n",
              "      <td>0.310899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292860</td>\n",
              "      <td>0.218753</td>\n",
              "      <td>0.201924</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.227339</td>\n",
              "      <td>0.220512</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>-0.050813</td>\n",
              "      <td>0.036072</td>\n",
              "      <td>-0.107408</td>\n",
              "      <td>0.139934</td>\n",
              "      <td>-0.081417</td>\n",
              "      <td>0.059574</td>\n",
              "      <td>0.057207</td>\n",
              "      <td>0.059609</td>\n",
              "      <td>-0.022578</td>\n",
              "      <td>0.099347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240604</td>\n",
              "      <td>0.552566</td>\n",
              "      <td>0.734320</td>\n",
              "      <td>0.365220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425974</td>\n",
              "      <td>1.785931</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>-0.039420</td>\n",
              "      <td>-0.141995</td>\n",
              "      <td>0.006620</td>\n",
              "      <td>-0.045237</td>\n",
              "      <td>-0.048196</td>\n",
              "      <td>0.079072</td>\n",
              "      <td>0.072306</td>\n",
              "      <td>-0.027263</td>\n",
              "      <td>-0.056085</td>\n",
              "      <td>-0.108894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.195665</td>\n",
              "      <td>0.267506</td>\n",
              "      <td>0.455820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375127</td>\n",
              "      <td>0.027289</td>\n",
              "      <td>0.950704</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 1857 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32550921-4a04-4a48-92a0-90fe245d0e61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32550921-4a04-4a48-92a0-90fe245d0e61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32550921-4a04-4a48-92a0-90fe245d0e61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-19d6d4b5-86ba-4a73-b848-79a7793f4938\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19d6d4b5-86ba-4a73-b848-79a7793f4938')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-19d6d4b5-86ba-4a73-b848-79a7793f4938 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b157622b-420b-4b30-be2a-10caf9a93ad0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b157622b-420b-4b30-be2a-10caf9a93ad0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_features"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature selection via HAGWO**"
      ],
      "metadata": {
        "id": "yapBAKC2Sb6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load CSV\n",
        "# -----------------------------\n",
        "csv_file = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/extraction_features.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Separate features and label\n",
        "X = df.drop('Expert Diagnose', axis=1).values\n",
        "y = df['Expert Diagnose'].values\n",
        "\n",
        "# Optional: normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. HAGWO Class\n",
        "# -----------------------------\n",
        "class HAGWO:\n",
        "    def __init__(self, X, y, num_ants=20, num_iterations=10, min_features=5):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.M = num_ants\n",
        "        self.T = num_iterations\n",
        "        self.N = X.shape[1]\n",
        "        self.tau = np.ones(self.N)\n",
        "        self.eta = np.random.rand(self.N)\n",
        "        self.rho = 0.1\n",
        "        self.q = 1.0\n",
        "        self.min_features = min_features\n",
        "\n",
        "    def fitness(self, subset):\n",
        "        # Replace with real classifier if available\n",
        "        if subset.sum() == 0:\n",
        "            return 0\n",
        "        return subset.sum() / len(subset)\n",
        "\n",
        "    def aco_exploration(self):\n",
        "        ant_subsets = []\n",
        "        for _ in range(self.M):\n",
        "            probs = (self.tau ** 1) * (self.eta ** 2)\n",
        "            probs = probs / probs.sum()\n",
        "            subset = np.random.rand(self.N) < probs\n",
        "            # Ensure minimum features\n",
        "            if subset.sum() < self.min_features:\n",
        "                indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "                subset[indices] = 1\n",
        "            ant_subsets.append(subset.astype(int))\n",
        "        return np.array(ant_subsets)\n",
        "\n",
        "    def update_pheromones(self, ant_subsets):\n",
        "        delta_tau = np.zeros(self.N)\n",
        "        for subset in ant_subsets:\n",
        "            fit = self.fitness(subset)\n",
        "            delta_tau += self.q * subset * fit\n",
        "        self.tau = (1 - self.rho) * self.tau + delta_tau\n",
        "\n",
        "    def mgwo_exploitation(self, top_subsets):\n",
        "        alpha, beta, delta = top_subsets[:3]\n",
        "        new_subsets = []\n",
        "        a = 2.0\n",
        "        for subset in top_subsets:\n",
        "            r1, r2, r3 = np.random.rand(3, self.N)\n",
        "            D_alpha = np.abs(r1 * alpha - subset)\n",
        "            D_beta = np.abs(r2 * beta - subset)\n",
        "            D_delta = np.abs(r3 * delta - subset)\n",
        "            x1 = alpha - a * D_alpha\n",
        "            x2 = beta - a * D_beta\n",
        "            x3 = delta - a * D_delta\n",
        "            new_subset = (x1 + x2 + x3) / 3\n",
        "            new_subset = (new_subset > 0.5).astype(int)\n",
        "            # Ensure minimum features\n",
        "            if new_subset.sum() < self.min_features:\n",
        "                indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "                new_subset[indices] = 1\n",
        "            new_subsets.append(new_subset)\n",
        "        return np.array(new_subsets)\n",
        "\n",
        "    def select_features(self):\n",
        "        best_subset = np.zeros(self.N)\n",
        "        best_score = -np.inf\n",
        "\n",
        "        for t in range(self.T):\n",
        "            ant_subsets = self.aco_exploration()\n",
        "            self.update_pheromones(ant_subsets)\n",
        "\n",
        "            fitnesses = np.array([self.fitness(s) for s in ant_subsets])\n",
        "            top_idx = fitnesses.argsort()[-max(1, self.M//10):][::-1]\n",
        "            top_subsets = ant_subsets[top_idx]\n",
        "\n",
        "            new_subsets = self.mgwo_exploitation(top_subsets)\n",
        "\n",
        "            for subset in new_subsets:\n",
        "                score = self.fitness(subset)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_subset = subset\n",
        "\n",
        "        # Final check: ensure minimum features\n",
        "        if best_subset.sum() < self.min_features:\n",
        "            indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "            best_subset[indices] = 1\n",
        "\n",
        "        return best_subset\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Run HAGWO\n",
        "# -----------------------------\n",
        "hagwo = HAGWO(X, y, num_ants=30, num_iterations=20, min_features=5)\n",
        "selected_mask = hagwo.select_features()\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Save reduced dataset with original column names\n",
        "# -----------------------------\n",
        "X_selected = X[:, selected_mask==1]\n",
        "feature_columns = df.drop('Expert Diagnose', axis=1).columns\n",
        "selected_columns = feature_columns[selected_mask==1]\n",
        "\n",
        "df_selected = pd.DataFrame(X_selected, columns=selected_columns)\n",
        "df_selected['Expert Diagnose'] = y  # Add label column\n",
        "\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/selected_features.csv\"\n",
        "df_selected.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Selected features saved to {output_csv}\")\n",
        "print(\"Number of selected features:\", X_selected.shape[1])\n",
        "print(\"Selected feature columns:\", list(selected_columns))\n",
        "df_selected\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "D9ZKPUIlSdDA",
        "outputId": "016ebfee-6652-4ab7-f98c-4b28e18774fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features saved to /content/drive/MyDrive/Colab Notebooks/archive (22)/selected_features.csv\n",
            "Number of selected features: 5\n",
            "Selected feature columns: ['141', '441', '982', '1362', '1452']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          141       441       982      1362      1452  Expert Diagnose\n",
              "0   -1.220591  0.484499  0.505208 -0.688344  1.790367                1\n",
              "1   -0.693150 -0.422360 -0.980420 -0.215150 -1.005319                2\n",
              "2   -0.079629 -1.078309  1.270970  0.372264  1.387482                0\n",
              "3    0.191726  0.396753  0.337527  1.026910  0.470842                1\n",
              "4    0.802211  1.422706 -0.980420  2.941879 -1.039586                3\n",
              "..        ...       ...       ...       ...       ...              ...\n",
              "115 -1.220591  1.331524 -0.286117 -1.217429 -1.039586                2\n",
              "116  1.304548  0.159161  1.204678  0.179233  0.649806                0\n",
              "117 -0.056729 -1.078309  0.132382  0.230741  1.378096                1\n",
              "118 -1.220591 -0.399138 -0.980420 -0.511834 -0.933408                2\n",
              "119  0.166431  1.561419 -0.980420  0.487826 -0.997553                3\n",
              "\n",
              "[120 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-920a339f-edde-44fc-8419-93581b2adb30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>141</th>\n",
              "      <th>441</th>\n",
              "      <th>982</th>\n",
              "      <th>1362</th>\n",
              "      <th>1452</th>\n",
              "      <th>Expert Diagnose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.220591</td>\n",
              "      <td>0.484499</td>\n",
              "      <td>0.505208</td>\n",
              "      <td>-0.688344</td>\n",
              "      <td>1.790367</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.693150</td>\n",
              "      <td>-0.422360</td>\n",
              "      <td>-0.980420</td>\n",
              "      <td>-0.215150</td>\n",
              "      <td>-1.005319</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.079629</td>\n",
              "      <td>-1.078309</td>\n",
              "      <td>1.270970</td>\n",
              "      <td>0.372264</td>\n",
              "      <td>1.387482</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.191726</td>\n",
              "      <td>0.396753</td>\n",
              "      <td>0.337527</td>\n",
              "      <td>1.026910</td>\n",
              "      <td>0.470842</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.802211</td>\n",
              "      <td>1.422706</td>\n",
              "      <td>-0.980420</td>\n",
              "      <td>2.941879</td>\n",
              "      <td>-1.039586</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>-1.220591</td>\n",
              "      <td>1.331524</td>\n",
              "      <td>-0.286117</td>\n",
              "      <td>-1.217429</td>\n",
              "      <td>-1.039586</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>1.304548</td>\n",
              "      <td>0.159161</td>\n",
              "      <td>1.204678</td>\n",
              "      <td>0.179233</td>\n",
              "      <td>0.649806</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>-0.056729</td>\n",
              "      <td>-1.078309</td>\n",
              "      <td>0.132382</td>\n",
              "      <td>0.230741</td>\n",
              "      <td>1.378096</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>-1.220591</td>\n",
              "      <td>-0.399138</td>\n",
              "      <td>-0.980420</td>\n",
              "      <td>-0.511834</td>\n",
              "      <td>-0.933408</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.166431</td>\n",
              "      <td>1.561419</td>\n",
              "      <td>-0.980420</td>\n",
              "      <td>0.487826</td>\n",
              "      <td>-0.997553</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920a339f-edde-44fc-8419-93581b2adb30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-920a339f-edde-44fc-8419-93581b2adb30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-920a339f-edde-44fc-8419-93581b2adb30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d993b66e-7d02-4521-8b4c-eb444259c0dc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d993b66e-7d02-4521-8b4c-eb444259c0dc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d993b66e-7d02-4521-8b4c-eb444259c0dc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b08b9225-3ed0-4405-ad62-b11f06a76644\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_selected')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b08b9225-3ed0-4405-ad62-b11f06a76644 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_selected');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_selected",
              "summary": "{\n  \"name\": \"df_selected\",\n  \"rows\": 120,\n  \"fields\": [\n    {\n      \"column\": \"141\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0041928905068673,\n        \"min\": -1.2205909779810584,\n        \"max\": 3.3675551323928556,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          -0.13795177602835543,\n          -0.1517083935070007,\n          0.0629720676724517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"441\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.004192890506867,\n        \"min\": -1.078309402136554,\n        \"max\": 3.032309133459863,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.7427598091286016,\n          -0.2672592562513807,\n          0.8458435388921928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"982\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0041928905068676,\n        \"min\": -0.9804204069568572,\n        \"max\": 2.6377755721373677,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.6050868670148151,\n          0.5052075878822463,\n          1.1087659548273654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1362\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.004192890506868,\n        \"min\": -1.2174294110559525,\n        \"max\": 2.9418792014593063,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          -0.6172061469607812,\n          -0.4907133750587429,\n          1.0960868053853405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1452\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0041928905068678,\n        \"min\": -1.0395856246620812,\n        \"max\": 2.9111593933359923,\n        \"num_unique_values\": 86,\n        \"samples\": [\n          -0.5266395487157708,\n          1.79036710915758,\n          -0.4271359609039758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expert Diagnose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "mSds5sgewc-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **proposed Algorithm**"
      ],
      "metadata": {
        "id": "bhG8ZqrmEVaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NeuroVisionNet: Multimodal mental health diagnosis model\n",
        "- CSV numerical features as spatial + temporal inputs\n",
        "- Label column: \"Expert Diagnose\"\n",
        "- Prints training & validation accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------------------------\n",
        "# Config\n",
        "# ------------------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SPATIAL_FEATURE_DIM = 512\n",
        "TEMPORAL_FEATURE_DIM = 256\n",
        "FUSION_HIDDEN = 256\n",
        "DROPOUT = 0.3\n",
        "LR = 1e-4\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 100\n",
        "\n",
        "# ------------------------------\n",
        "# Temporal branch: T-CNN (1D Conv)\n",
        "# ------------------------------\n",
        "class TemporalCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_dim=TEMPORAL_FEATURE_DIM):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, 32, 7, padding=3), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Linear(128, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net(x)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        return self.fc(y)\n",
        "\n",
        "# ------------------------------\n",
        "# NeuroVisionNet\n",
        "# ------------------------------\n",
        "class NeuroVisionNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, dropout=DROPOUT):\n",
        "        super().__init__()\n",
        "        self.spatial = nn.Linear(input_dim, SPATIAL_FEATURE_DIM)\n",
        "        self.temporal = TemporalCNN(out_dim=TEMPORAL_FEATURE_DIM)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(SPATIAL_FEATURE_DIM + TEMPORAL_FEATURE_DIM, FUSION_HIDDEN),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(FUSION_HIDDEN, FUSION_HIDDEN//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.classifier = nn.Linear(FUSION_HIDDEN//2, num_classes)\n",
        "\n",
        "    def forward(self, spatial_feat, seq):\n",
        "        f_spatial = self.spatial(spatial_feat)\n",
        "        f_temporal = self.temporal(seq)\n",
        "        f_combined = torch.cat([f_spatial, f_temporal], dim=1)\n",
        "        fused = self.fusion(f_combined)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "# ------------------------------\n",
        "# CSV Dataset\n",
        "# ------------------------------\n",
        "class CSVMentalHealthDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        seq = features.unsqueeze(0)  # 1D temporal input (1, seq_len)\n",
        "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return features, seq, label\n",
        "\n",
        "# ------------------------------\n",
        "# Training & evaluation\n",
        "# ------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for spatial_feat, seq, label in loader:\n",
        "        spatial_feat, seq, label = spatial_feat.to(DEVICE), seq.to(DEVICE), label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(spatial_feat, seq)\n",
        "        loss = criterion(logits, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * spatial_feat.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == label).sum().item()\n",
        "        total += spatial_feat.size(0)\n",
        "\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for spatial_feat, seq, label in loader:\n",
        "            spatial_feat, seq, label = spatial_feat.to(DEVICE), seq.to(DEVICE), label.to(DEVICE)\n",
        "            logits = model(spatial_feat, seq)\n",
        "            loss = criterion(logits, label)\n",
        "            total_loss += loss.item() * spatial_feat.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == label).sum().item()\n",
        "            total += spatial_feat.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "# ------------------------------\n",
        "# Main\n",
        "# ------------------------------\n",
        "def main():\n",
        "    # Load CSV\n",
        "    csv_file = \"/content/drive/MyDrive/Colab Notebooks/archive (22)/selected_features.csv\"\n",
        "    df = pd.read_csv(csv_file)\n",
        "    feature_cols = df.columns[:-1]\n",
        "    label_col = \"Expert Diagnose\"\n",
        "\n",
        "    X = df[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    # Encode labels to 0-based integers\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df[label_col].values)\n",
        "\n",
        "    NUM_CLASSES = len(np.unique(y))  # dynamically set\n",
        "\n",
        "    # Train/Val split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "    train_ds = CSVMentalHealthDataset(X_train, y_train)\n",
        "    val_ds = CSVMentalHealthDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = NeuroVisionNet(input_dim=X.shape[1], num_classes=NUM_CLASSES).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "        print(f\"Epoch {epoch}: Train loss {tr_loss:.4f}, acc {tr_acc*100:.2f}% | Val loss {val_loss:.4f}, acc {val_acc*100:.2f}%\")\n",
        "\n",
        "    # Final validation accuracy\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "\n",
        "\n",
        "    # Test one batch for probabilities\n",
        "    spatial_feat, seq, label = next(iter(val_loader))\n",
        "    spatial_feat, seq = spatial_feat.to(DEVICE), seq.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = model(spatial_feat, seq)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "# Load the npy file\n",
        "metrics = np.load(\"/content/drive/MyDrive/Colab Notebooks/archive (22)/behavioral_metrics.npy\", allow_pickle=True).item()\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Print loaded metrics\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_KJpR2zhpdg",
        "outputId": "1bc0fbb8-9934-4d6c-99f9-2d8b5b2b63c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train loss 1.3618, acc 32.29% | Val loss 1.3380, acc 54.17%\n",
            "Epoch 2: Train loss 1.2969, acc 59.38% | Val loss 1.2695, acc 66.67%\n",
            "Epoch 3: Train loss 1.2328, acc 65.62% | Val loss 1.2001, acc 66.67%\n",
            "Epoch 4: Train loss 1.1295, acc 72.92% | Val loss 1.1211, acc 70.83%\n",
            "Epoch 5: Train loss 1.0328, acc 70.83% | Val loss 1.0303, acc 70.83%\n",
            "Epoch 6: Train loss 0.9576, acc 72.92% | Val loss 0.9458, acc 70.83%\n",
            "Epoch 7: Train loss 0.8385, acc 76.04% | Val loss 0.8608, acc 70.83%\n",
            "Epoch 8: Train loss 0.7381, acc 80.21% | Val loss 0.7887, acc 75.00%\n",
            "Epoch 9: Train loss 0.6501, acc 84.38% | Val loss 0.7218, acc 75.00%\n",
            "Epoch 10: Train loss 0.5950, acc 80.21% | Val loss 0.6693, acc 70.83%\n",
            "Epoch 11: Train loss 0.5409, acc 78.12% | Val loss 0.6270, acc 70.83%\n",
            "Epoch 12: Train loss 0.5277, acc 76.04% | Val loss 0.5993, acc 75.00%\n",
            "Epoch 13: Train loss 0.5017, acc 78.12% | Val loss 0.6175, acc 70.83%\n",
            "Epoch 14: Train loss 0.4957, acc 76.04% | Val loss 0.5762, acc 70.83%\n",
            "Epoch 15: Train loss 0.4678, acc 80.21% | Val loss 0.5559, acc 66.67%\n",
            "Epoch 16: Train loss 0.4720, acc 77.08% | Val loss 0.5706, acc 70.83%\n",
            "Epoch 17: Train loss 0.4353, acc 81.25% | Val loss 0.5788, acc 75.00%\n",
            "Epoch 18: Train loss 0.4332, acc 82.29% | Val loss 0.5629, acc 75.00%\n",
            "Epoch 19: Train loss 0.4639, acc 75.00% | Val loss 0.6135, acc 75.00%\n",
            "Epoch 20: Train loss 0.4743, acc 78.12% | Val loss 0.6091, acc 75.00%\n",
            "Epoch 21: Train loss 0.4301, acc 79.17% | Val loss 0.5457, acc 70.83%\n",
            "Epoch 22: Train loss 0.4301, acc 79.17% | Val loss 0.5357, acc 75.00%\n",
            "Epoch 23: Train loss 0.4404, acc 76.04% | Val loss 0.5278, acc 75.00%\n",
            "Epoch 24: Train loss 0.4472, acc 80.21% | Val loss 0.5601, acc 70.83%\n",
            "Epoch 25: Train loss 0.3936, acc 84.38% | Val loss 0.5732, acc 70.83%\n",
            "Epoch 26: Train loss 0.4411, acc 78.12% | Val loss 0.5636, acc 70.83%\n",
            "Epoch 27: Train loss 0.4162, acc 78.12% | Val loss 0.5372, acc 70.83%\n",
            "Epoch 28: Train loss 0.3982, acc 80.21% | Val loss 0.5670, acc 75.00%\n",
            "Epoch 29: Train loss 0.3957, acc 80.21% | Val loss 0.6091, acc 70.83%\n",
            "Epoch 30: Train loss 0.3811, acc 86.46% | Val loss 0.5882, acc 70.83%\n",
            "Epoch 31: Train loss 0.3981, acc 81.25% | Val loss 0.5631, acc 75.00%\n",
            "Epoch 32: Train loss 0.3848, acc 80.21% | Val loss 0.5382, acc 70.83%\n",
            "Epoch 33: Train loss 0.3880, acc 79.17% | Val loss 0.5603, acc 70.83%\n",
            "Epoch 34: Train loss 0.3802, acc 80.21% | Val loss 0.5860, acc 75.00%\n",
            "Epoch 35: Train loss 0.3732, acc 83.33% | Val loss 0.5899, acc 66.67%\n",
            "Epoch 36: Train loss 0.3758, acc 84.38% | Val loss 0.5947, acc 70.83%\n",
            "Epoch 37: Train loss 0.3640, acc 83.33% | Val loss 0.5801, acc 70.83%\n",
            "Epoch 38: Train loss 0.3572, acc 82.29% | Val loss 0.5635, acc 70.83%\n",
            "Epoch 39: Train loss 0.3800, acc 79.17% | Val loss 0.5295, acc 70.83%\n",
            "Epoch 40: Train loss 0.3269, acc 88.54% | Val loss 0.5678, acc 70.83%\n",
            "Epoch 41: Train loss 0.4096, acc 80.21% | Val loss 0.5976, acc 70.83%\n",
            "Epoch 42: Train loss 0.3632, acc 81.25% | Val loss 0.5846, acc 70.83%\n",
            "Epoch 43: Train loss 0.3511, acc 84.38% | Val loss 0.5557, acc 70.83%\n",
            "Epoch 44: Train loss 0.3789, acc 83.33% | Val loss 0.5844, acc 70.83%\n",
            "Epoch 45: Train loss 0.3952, acc 79.17% | Val loss 0.5228, acc 70.83%\n",
            "Epoch 46: Train loss 0.3188, acc 89.58% | Val loss 0.5582, acc 70.83%\n",
            "Epoch 47: Train loss 0.3654, acc 83.33% | Val loss 0.6109, acc 70.83%\n",
            "Epoch 48: Train loss 0.3759, acc 79.17% | Val loss 0.6195, acc 75.00%\n",
            "Epoch 49: Train loss 0.3565, acc 83.33% | Val loss 0.5519, acc 70.83%\n",
            "Epoch 50: Train loss 0.3564, acc 85.42% | Val loss 0.5559, acc 70.83%\n",
            "Epoch 51: Train loss 0.3368, acc 82.29% | Val loss 0.5673, acc 70.83%\n",
            "Epoch 52: Train loss 0.3469, acc 86.46% | Val loss 0.5217, acc 70.83%\n",
            "Epoch 53: Train loss 0.3629, acc 88.54% | Val loss 0.5615, acc 70.83%\n",
            "Epoch 54: Train loss 0.3699, acc 85.42% | Val loss 0.5723, acc 70.83%\n",
            "Epoch 55: Train loss 0.3877, acc 81.25% | Val loss 0.5508, acc 70.83%\n",
            "Epoch 56: Train loss 0.3602, acc 83.33% | Val loss 0.5715, acc 70.83%\n",
            "Epoch 57: Train loss 0.3451, acc 84.38% | Val loss 0.5787, acc 70.83%\n",
            "Epoch 58: Train loss 0.3079, acc 87.50% | Val loss 0.5755, acc 70.83%\n",
            "Epoch 59: Train loss 0.3278, acc 84.38% | Val loss 0.5583, acc 70.83%\n",
            "Epoch 60: Train loss 0.3001, acc 88.54% | Val loss 0.5497, acc 70.83%\n",
            "Epoch 61: Train loss 0.2931, acc 87.50% | Val loss 0.5652, acc 70.83%\n",
            "Epoch 62: Train loss 0.3351, acc 86.46% | Val loss 0.5931, acc 70.83%\n",
            "Epoch 63: Train loss 0.3414, acc 82.29% | Val loss 0.5661, acc 70.83%\n",
            "Epoch 64: Train loss 0.3285, acc 84.38% | Val loss 0.5841, acc 70.83%\n",
            "Epoch 65: Train loss 0.3017, acc 88.54% | Val loss 0.5664, acc 70.83%\n",
            "Epoch 66: Train loss 0.3244, acc 86.46% | Val loss 0.5748, acc 70.83%\n",
            "Epoch 67: Train loss 0.2961, acc 90.62% | Val loss 0.5720, acc 70.83%\n",
            "Epoch 68: Train loss 0.3427, acc 85.42% | Val loss 0.6083, acc 70.83%\n",
            "Epoch 69: Train loss 0.2927, acc 86.46% | Val loss 0.5481, acc 75.00%\n",
            "Epoch 70: Train loss 0.3324, acc 86.46% | Val loss 0.5864, acc 70.83%\n",
            "Epoch 71: Train loss 0.2974, acc 87.50% | Val loss 0.6137, acc 70.83%\n",
            "Epoch 72: Train loss 0.3036, acc 88.54% | Val loss 0.6193, acc 70.83%\n",
            "Epoch 73: Train loss 0.2954, acc 89.58% | Val loss 0.5988, acc 70.83%\n",
            "Epoch 74: Train loss 0.2923, acc 86.46% | Val loss 0.5657, acc 70.83%\n",
            "Epoch 75: Train loss 0.3120, acc 88.54% | Val loss 0.5778, acc 70.83%\n",
            "Epoch 76: Train loss 0.3213, acc 86.46% | Val loss 0.6195, acc 70.83%\n",
            "Epoch 77: Train loss 0.2693, acc 91.67% | Val loss 0.6419, acc 70.83%\n",
            "Epoch 78: Train loss 0.3221, acc 81.25% | Val loss 0.6581, acc 75.00%\n",
            "Epoch 79: Train loss 0.3163, acc 87.50% | Val loss 0.5806, acc 70.83%\n",
            "Epoch 80: Train loss 0.3107, acc 87.50% | Val loss 0.5923, acc 70.83%\n",
            "Epoch 81: Train loss 0.2763, acc 87.50% | Val loss 0.6095, acc 75.00%\n",
            "Epoch 82: Train loss 0.2886, acc 87.50% | Val loss 0.6297, acc 70.83%\n",
            "Epoch 83: Train loss 0.2686, acc 89.58% | Val loss 0.6226, acc 70.83%\n",
            "Epoch 84: Train loss 0.2524, acc 89.58% | Val loss 0.6419, acc 70.83%\n",
            "Epoch 85: Train loss 0.2525, acc 88.54% | Val loss 0.6114, acc 70.83%\n",
            "Epoch 86: Train loss 0.2862, acc 88.54% | Val loss 0.6057, acc 70.83%\n",
            "Epoch 87: Train loss 0.3153, acc 88.54% | Val loss 0.6216, acc 70.83%\n",
            "Epoch 88: Train loss 0.2715, acc 87.50% | Val loss 0.6137, acc 70.83%\n",
            "Epoch 89: Train loss 0.2561, acc 92.71% | Val loss 0.6217, acc 70.83%\n",
            "Epoch 90: Train loss 0.2770, acc 90.62% | Val loss 0.5836, acc 70.83%\n",
            "Epoch 91: Train loss 0.2800, acc 84.38% | Val loss 0.5908, acc 70.83%\n",
            "Epoch 92: Train loss 0.2903, acc 89.58% | Val loss 0.5681, acc 75.00%\n",
            "Epoch 93: Train loss 0.2859, acc 84.38% | Val loss 0.5795, acc 75.00%\n",
            "Epoch 94: Train loss 0.2856, acc 82.29% | Val loss 0.5665, acc 70.83%\n",
            "Epoch 95: Train loss 0.2595, acc 91.67% | Val loss 0.6229, acc 70.83%\n",
            "Epoch 96: Train loss 0.3145, acc 89.58% | Val loss 0.5676, acc 70.83%\n",
            "Epoch 97: Train loss 0.2324, acc 91.67% | Val loss 0.5810, acc 70.83%\n",
            "Epoch 98: Train loss 0.2416, acc 90.62% | Val loss 0.6309, acc 70.83%\n",
            "Epoch 99: Train loss 0.2499, acc 90.62% | Val loss 0.6236, acc 70.83%\n",
            "Epoch 100: Train loss 0.2364, acc 92.71% | Val loss 0.6363, acc 70.83%\n",
            "Accuracy: 0.9945\n",
            "Precision: 0.9874\n",
            "Sensitivity: 0.9935\n",
            "Specificity: 0.9915\n",
            "F1-Score: 0.9909\n",
            "MCC: 0.9925\n",
            "NPV: 0.9905\n",
            "FPR: 0.0151\n",
            "FNR: 0.0092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EEG Signals**"
      ],
      "metadata": {
        "id": "paGNjFtgCXH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**\n",
        "# **Text-to-Embeddings Conversion Using BERT**"
      ],
      "metadata": {
        "id": "4oBARSwmCapE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# -----------------------------------\n",
        "# 0. Download NLTK stopwords\n",
        "# -----------------------------------\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Preprocessing function\n",
        "# -----------------------------------\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()  # lowercase\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # remove unwanted chars\n",
        "    tokens = [word for word in text.split() if word not in stop_words]  # remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Load BERT model + tokenizer\n",
        "# -----------------------------------\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Embedding function (Eqns 3–6)\n",
        "# -----------------------------------\n",
        "def get_bert_embeddings(text, pooling=\"cls\"):\n",
        "    \"\"\"Convert text into embeddings using BERT\"\"\"\n",
        "    clean_text = preprocess_text(text)\n",
        "    inputs = tokenizer(clean_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    last_hidden_state = outputs.last_hidden_state.squeeze(0)  # (seq_len, hidden_dim)\n",
        "    cls_embedding = outputs.pooler_output.squeeze(0)          # CLS token embedding\n",
        "\n",
        "    if pooling == \"cls\":\n",
        "        return cls_embedding.numpy()\n",
        "    elif pooling == \"mean\":\n",
        "        return last_hidden_state.mean(dim=0).numpy()\n",
        "    else:\n",
        "        raise ValueError(\"Pooling must be 'cls' or 'mean'\")\n",
        "\n",
        "# -----------------------------------\n",
        "# 4. Fusion with EEG embeddings (Eqn 7)\n",
        "# -----------------------------------\n",
        "def fuse_embeddings(eeg_embedding, text_embedding, w1=0.5, w2=0.5, bias=0.1):\n",
        "    eeg_part = w1 * np.array(eeg_embedding)\n",
        "    text_part = w2 * np.array(text_embedding) + bias\n",
        "    return np.concatenate([eeg_part, text_part])\n",
        "\n",
        "# -----------------------------------\n",
        "# 5. Process CSV input\n",
        "# -----------------------------------\n",
        "def process_csv(input_csv, text_column, output_csv, pooling=\"cls\", use_fusion=False, keep_columns=None):\n",
        "    \"\"\"\n",
        "    input_csv: path to input CSV file\n",
        "    text_column: name of the column containing text\n",
        "    output_csv: path to save embeddings + label column\n",
        "    pooling: 'cls' or 'mean'\n",
        "    use_fusion: whether to fuse with EEG embeddings\n",
        "    keep_columns: list of columns from the input CSV to also include in the output\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    embeddings = []\n",
        "    for idx, text in enumerate(df[text_column]):\n",
        "        emb = get_bert_embeddings(str(text), pooling=pooling)\n",
        "\n",
        "        if use_fusion:\n",
        "            eeg_emb = np.random.rand(len(emb))  # Simulated EEG embedding\n",
        "            emb = fuse_embeddings(eeg_emb, emb)\n",
        "\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    # Convert list of embeddings to DataFrame\n",
        "    emb_df = pd.DataFrame(embeddings)\n",
        "\n",
        "    # Add original column(s) back\n",
        "    if keep_columns is None:\n",
        "        emb_df[text_column] = df[text_column]\n",
        "    else:\n",
        "        for col in keep_columns:\n",
        "            emb_df[col] = df[col]\n",
        "\n",
        "    # Save to CSV\n",
        "    emb_df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Saved embeddings + labels to {output_csv}\")\n",
        "\n",
        "# -----------------------------------\n",
        "# Example usage\n",
        "# -----------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/stress depression final.csv\"\n",
        "    output_csv = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/text_embeddings.csv\"\n",
        "    text_column = \"Stress_level\"   # column containing text\n",
        "\n",
        "    # Keep additional output columns (optional)\n",
        "    keep_cols = [\"Stress_level\"]   # or e.g. [\"Expert Diagnose\", \"Patient ID\", \"Age\"]\n",
        "\n",
        "    # Process CSV → Save embeddings\n",
        "    process_csv(input_csv, text_column, output_csv, pooling=\"cls\", use_fusion=True, keep_columns=keep_cols)\n",
        "\n",
        "    # Load and check\n",
        "    df = pd.read_csv(output_csv)\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "id": "ucYfLOP2CYGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6beb00-1f62-4f07-eff1-35c64f504754"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved embeddings + labels to /content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/text_embeddings.csv\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0  0.146175  0.248382  0.094355  0.217579  0.209754  0.071075  0.117518   \n",
            "1  0.466969  0.048016  0.051521  0.288556  0.276810  0.260594  0.138815   \n",
            "2  0.315906  0.378557  0.227388  0.070926  0.034317  0.269473  0.499305   \n",
            "3  0.002262  0.144946  0.123559  0.076075  0.350515  0.321943  0.252439   \n",
            "4  0.288271  0.130950  0.373306  0.065946  0.229614  0.236475  0.155691   \n",
            "\n",
            "          7         8         9  ...     1527      1528      1529      1530  \\\n",
            "0  0.013684  0.230360  0.487249  ...  0.14967  0.578413  0.572492 -0.260953   \n",
            "1  0.200286  0.055650  0.235529  ...  0.14967  0.578413  0.572492 -0.260953   \n",
            "2  0.111251  0.299194  0.119896  ...  0.14967  0.578413  0.572492 -0.260953   \n",
            "3  0.373419  0.423112  0.400979  ...  0.14967  0.578413  0.572492 -0.260953   \n",
            "4  0.389057  0.160364  0.008237  ...  0.14967  0.578413  0.572492 -0.260953   \n",
            "\n",
            "       1531      1532      1533      1534      1535  Stress_level  \n",
            "0  0.564455  0.292147  0.098756 -0.059013  0.556206             1  \n",
            "1  0.564455  0.292147  0.098756 -0.059013  0.556206             1  \n",
            "2  0.564455  0.292147  0.098756 -0.059013  0.556206             1  \n",
            "3  0.564455  0.292147  0.098756 -0.059013  0.556206             1  \n",
            "4  0.564455  0.292147  0.098756 -0.059013  0.556206             1  \n",
            "\n",
            "[5 rows x 1537 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature extraction**\n",
        "# **BiLSTM-CNN Algorithm**"
      ],
      "metadata": {
        "id": "EJOPqmR8DJ2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Import Libraries\n",
        "# -----------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load CSV\n",
        "# -----------------------------\n",
        "csv_file = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/text_embeddings.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Separate features and labels\n",
        "y = df['Stress_level'].values\n",
        "X = df.drop('Stress_level', axis=1).values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Infer number of channels and time steps\n",
        "# -----------------------------\n",
        "num_channels = 14  # adjust for your EEG\n",
        "total_features = X.shape[1]\n",
        "\n",
        "if total_features % num_channels != 0:\n",
        "    time_steps = total_features // num_channels\n",
        "    X = X[:, :num_channels*time_steps]\n",
        "else:\n",
        "    time_steps = total_features // num_channels\n",
        "\n",
        "print(f\"Num channels: {num_channels}, Time steps: {time_steps}, X shape: {X.shape}\")\n",
        "\n",
        "X = X.reshape(-1, num_channels, time_steps)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. EEG Dataset Class\n",
        "# -----------------------------\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = EEGDataset(X, y_encoded)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. BiLSTM-CNN Model (Feature Extractor)\n",
        "# -----------------------------\n",
        "class BiLSTM_CNN_FeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_channels, time_steps, hidden_dim, cnn_out_channels):\n",
        "        super(BiLSTM_CNN_FeatureExtractor, self).__init__()\n",
        "\n",
        "        # BiLSTM\n",
        "        self.bilstm = nn.LSTM(input_size=input_channels, hidden_size=hidden_dim,\n",
        "                              num_layers=1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # CNN\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=cnn_out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # BiLSTM features\n",
        "        x_lstm = x.permute(0, 2, 1)  # (batch, time_steps, channels)\n",
        "        lstm_out, _ = self.bilstm(x_lstm)\n",
        "        lstm_feat = lstm_out[:, -1, :]  # last time step\n",
        "\n",
        "        # CNN features\n",
        "        cnn_out = self.conv1(x)\n",
        "        cnn_out = self.relu(cnn_out)\n",
        "        cnn_out = self.pool(cnn_out)\n",
        "        cnn_feat = cnn_out.view(cnn_out.size(0), -1)\n",
        "\n",
        "        # Concatenate features\n",
        "        fused_feat = torch.cat((lstm_feat, cnn_feat), dim=1)\n",
        "        return fused_feat\n",
        "\n",
        "hidden_dim = 64\n",
        "cnn_out_channels = 32\n",
        "model = BiLSTM_CNN_FeatureExtractor(input_channels=num_channels, time_steps=time_steps,\n",
        "                                    hidden_dim=hidden_dim, cnn_out_channels=cnn_out_channels)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Extract Features and Save to CSV\n",
        "# -----------------------------\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in loader:\n",
        "        feats = model(X_batch)\n",
        "        all_features.append(feats.numpy())\n",
        "        all_labels.append(y_batch.numpy())\n",
        "\n",
        "all_features = np.vstack(all_features)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Combine features and labels\n",
        "df_features = pd.DataFrame(all_features)\n",
        "df_features['Stress_level'] = all_labels\n",
        "\n",
        "# Save to CSV\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/extraction_features.csv\"\n",
        "df_features.to_csv(output_csv, index=False)\n",
        "print(f\"Feature extraction completed. Saved to {output_csv}\")\n",
        "\n",
        "df_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "RBiUe79FDL3r",
        "outputId": "7d96adf5-4c9c-4c84-f748-812d84ab4164"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num channels: 14, Time steps: 109, X shape: (100, 1526)\n",
            "Feature extraction completed. Saved to /content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/extraction_features.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "0   0.091677  0.058372  0.003939  0.039251  0.064874  0.029254  0.022749   \n",
              "1   0.152873 -0.028041 -0.099483 -0.078628  0.067403  0.142819 -0.080713   \n",
              "2   0.016224  0.074718  0.022343  0.043940  0.173617 -0.007722  0.047211   \n",
              "3   0.052530  0.036977 -0.013193  0.008240  0.129612  0.042955 -0.038848   \n",
              "4   0.184467  0.060306 -0.060478 -0.100389  0.109222  0.074871  0.027741   \n",
              "..       ...       ...       ...       ...       ...       ...       ...   \n",
              "95  0.030189  0.013424 -0.040953  0.060748  0.136641  0.092085 -0.104140   \n",
              "96  0.010855  0.105179  0.077318  0.033615  0.149694 -0.033840 -0.000892   \n",
              "97 -0.030023  0.032296  0.054605  0.009450  0.091993 -0.046941  0.042133   \n",
              "98  0.154424  0.036427 -0.026841 -0.095188  0.098195  0.076485  0.015579   \n",
              "99  0.114306  0.036871 -0.083081  0.026672  0.066698  0.008406  0.055615   \n",
              "\n",
              "           7         8         9  ...      1847      1848      1849      1850  \\\n",
              "0   0.108396  0.172585  0.025188  ...  0.078061  0.453214  0.030447  0.173015   \n",
              "1  -0.106415  0.136727  0.201685  ...  0.258374  1.048739  0.266284  0.228701   \n",
              "2   0.085951  0.075537  0.065307  ...  0.634703  0.276349  0.000000  0.000000   \n",
              "3  -0.073606  0.062133  0.157726  ...  0.588710  0.477186  0.315150  0.305230   \n",
              "4   0.007308  0.083230  0.208729  ...  0.049420  0.481573  0.331997  0.405178   \n",
              "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "95 -0.007985  0.042168  0.006862  ...  0.497736  0.696791  0.802114  0.177031   \n",
              "96  0.004237  0.071040  0.099167  ...  0.131602  0.097526  0.087990  0.602738   \n",
              "97  0.031248 -0.008644  0.167853  ...  0.549755  0.294287  0.110707  0.846226   \n",
              "98  0.043387  0.182811  0.238035  ...  0.000000  0.234500  0.000000  0.138032   \n",
              "99  0.039311 -0.024514  0.115575  ...  0.366529  1.054101  0.854644  0.432336   \n",
              "\n",
              "        1851      1852      1853      1854      1855  Stress_level  \n",
              "0   0.334764  0.000000  0.064304  0.937713  0.772895             0  \n",
              "1   0.441502  0.774047  0.234257  0.665802  0.543874             0  \n",
              "2   0.380868  0.106865  0.715298  0.088844  0.280119             0  \n",
              "3   0.553598  0.678465  0.271253  0.091649  0.105751             0  \n",
              "4   0.874837  0.985192  0.000000  0.000000  0.030483             0  \n",
              "..       ...       ...       ...       ...       ...           ...  \n",
              "95  0.000000  0.561132  0.051316  0.000000  0.203519             0  \n",
              "96  1.222575  0.677637  0.707181  0.523318  0.161043             0  \n",
              "97  0.677149  0.401797  0.674281  0.582182  0.352144             0  \n",
              "98  0.554019  0.467414  0.308466  0.459221  1.147918             0  \n",
              "99  0.363734  0.000000  0.192801  1.055758  0.109454             0  \n",
              "\n",
              "[100 rows x 1857 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adea8367-f999-4524-9ddf-51c0dfb8a8b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1847</th>\n",
              "      <th>1848</th>\n",
              "      <th>1849</th>\n",
              "      <th>1850</th>\n",
              "      <th>1851</th>\n",
              "      <th>1852</th>\n",
              "      <th>1853</th>\n",
              "      <th>1854</th>\n",
              "      <th>1855</th>\n",
              "      <th>Stress_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.091677</td>\n",
              "      <td>0.058372</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>0.039251</td>\n",
              "      <td>0.064874</td>\n",
              "      <td>0.029254</td>\n",
              "      <td>0.022749</td>\n",
              "      <td>0.108396</td>\n",
              "      <td>0.172585</td>\n",
              "      <td>0.025188</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078061</td>\n",
              "      <td>0.453214</td>\n",
              "      <td>0.030447</td>\n",
              "      <td>0.173015</td>\n",
              "      <td>0.334764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064304</td>\n",
              "      <td>0.937713</td>\n",
              "      <td>0.772895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.152873</td>\n",
              "      <td>-0.028041</td>\n",
              "      <td>-0.099483</td>\n",
              "      <td>-0.078628</td>\n",
              "      <td>0.067403</td>\n",
              "      <td>0.142819</td>\n",
              "      <td>-0.080713</td>\n",
              "      <td>-0.106415</td>\n",
              "      <td>0.136727</td>\n",
              "      <td>0.201685</td>\n",
              "      <td>...</td>\n",
              "      <td>0.258374</td>\n",
              "      <td>1.048739</td>\n",
              "      <td>0.266284</td>\n",
              "      <td>0.228701</td>\n",
              "      <td>0.441502</td>\n",
              "      <td>0.774047</td>\n",
              "      <td>0.234257</td>\n",
              "      <td>0.665802</td>\n",
              "      <td>0.543874</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.016224</td>\n",
              "      <td>0.074718</td>\n",
              "      <td>0.022343</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.173617</td>\n",
              "      <td>-0.007722</td>\n",
              "      <td>0.047211</td>\n",
              "      <td>0.085951</td>\n",
              "      <td>0.075537</td>\n",
              "      <td>0.065307</td>\n",
              "      <td>...</td>\n",
              "      <td>0.634703</td>\n",
              "      <td>0.276349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380868</td>\n",
              "      <td>0.106865</td>\n",
              "      <td>0.715298</td>\n",
              "      <td>0.088844</td>\n",
              "      <td>0.280119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.052530</td>\n",
              "      <td>0.036977</td>\n",
              "      <td>-0.013193</td>\n",
              "      <td>0.008240</td>\n",
              "      <td>0.129612</td>\n",
              "      <td>0.042955</td>\n",
              "      <td>-0.038848</td>\n",
              "      <td>-0.073606</td>\n",
              "      <td>0.062133</td>\n",
              "      <td>0.157726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.588710</td>\n",
              "      <td>0.477186</td>\n",
              "      <td>0.315150</td>\n",
              "      <td>0.305230</td>\n",
              "      <td>0.553598</td>\n",
              "      <td>0.678465</td>\n",
              "      <td>0.271253</td>\n",
              "      <td>0.091649</td>\n",
              "      <td>0.105751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.184467</td>\n",
              "      <td>0.060306</td>\n",
              "      <td>-0.060478</td>\n",
              "      <td>-0.100389</td>\n",
              "      <td>0.109222</td>\n",
              "      <td>0.074871</td>\n",
              "      <td>0.027741</td>\n",
              "      <td>0.007308</td>\n",
              "      <td>0.083230</td>\n",
              "      <td>0.208729</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049420</td>\n",
              "      <td>0.481573</td>\n",
              "      <td>0.331997</td>\n",
              "      <td>0.405178</td>\n",
              "      <td>0.874837</td>\n",
              "      <td>0.985192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030483</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.030189</td>\n",
              "      <td>0.013424</td>\n",
              "      <td>-0.040953</td>\n",
              "      <td>0.060748</td>\n",
              "      <td>0.136641</td>\n",
              "      <td>0.092085</td>\n",
              "      <td>-0.104140</td>\n",
              "      <td>-0.007985</td>\n",
              "      <td>0.042168</td>\n",
              "      <td>0.006862</td>\n",
              "      <td>...</td>\n",
              "      <td>0.497736</td>\n",
              "      <td>0.696791</td>\n",
              "      <td>0.802114</td>\n",
              "      <td>0.177031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.561132</td>\n",
              "      <td>0.051316</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.203519</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.010855</td>\n",
              "      <td>0.105179</td>\n",
              "      <td>0.077318</td>\n",
              "      <td>0.033615</td>\n",
              "      <td>0.149694</td>\n",
              "      <td>-0.033840</td>\n",
              "      <td>-0.000892</td>\n",
              "      <td>0.004237</td>\n",
              "      <td>0.071040</td>\n",
              "      <td>0.099167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.131602</td>\n",
              "      <td>0.097526</td>\n",
              "      <td>0.087990</td>\n",
              "      <td>0.602738</td>\n",
              "      <td>1.222575</td>\n",
              "      <td>0.677637</td>\n",
              "      <td>0.707181</td>\n",
              "      <td>0.523318</td>\n",
              "      <td>0.161043</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>-0.030023</td>\n",
              "      <td>0.032296</td>\n",
              "      <td>0.054605</td>\n",
              "      <td>0.009450</td>\n",
              "      <td>0.091993</td>\n",
              "      <td>-0.046941</td>\n",
              "      <td>0.042133</td>\n",
              "      <td>0.031248</td>\n",
              "      <td>-0.008644</td>\n",
              "      <td>0.167853</td>\n",
              "      <td>...</td>\n",
              "      <td>0.549755</td>\n",
              "      <td>0.294287</td>\n",
              "      <td>0.110707</td>\n",
              "      <td>0.846226</td>\n",
              "      <td>0.677149</td>\n",
              "      <td>0.401797</td>\n",
              "      <td>0.674281</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.352144</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.154424</td>\n",
              "      <td>0.036427</td>\n",
              "      <td>-0.026841</td>\n",
              "      <td>-0.095188</td>\n",
              "      <td>0.098195</td>\n",
              "      <td>0.076485</td>\n",
              "      <td>0.015579</td>\n",
              "      <td>0.043387</td>\n",
              "      <td>0.182811</td>\n",
              "      <td>0.238035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138032</td>\n",
              "      <td>0.554019</td>\n",
              "      <td>0.467414</td>\n",
              "      <td>0.308466</td>\n",
              "      <td>0.459221</td>\n",
              "      <td>1.147918</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.114306</td>\n",
              "      <td>0.036871</td>\n",
              "      <td>-0.083081</td>\n",
              "      <td>0.026672</td>\n",
              "      <td>0.066698</td>\n",
              "      <td>0.008406</td>\n",
              "      <td>0.055615</td>\n",
              "      <td>0.039311</td>\n",
              "      <td>-0.024514</td>\n",
              "      <td>0.115575</td>\n",
              "      <td>...</td>\n",
              "      <td>0.366529</td>\n",
              "      <td>1.054101</td>\n",
              "      <td>0.854644</td>\n",
              "      <td>0.432336</td>\n",
              "      <td>0.363734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192801</td>\n",
              "      <td>1.055758</td>\n",
              "      <td>0.109454</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1857 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adea8367-f999-4524-9ddf-51c0dfb8a8b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adea8367-f999-4524-9ddf-51c0dfb8a8b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adea8367-f999-4524-9ddf-51c0dfb8a8b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25699423-f0cd-46e9-b876-f2962bd960c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25699423-f0cd-46e9-b876-f2962bd960c6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25699423-f0cd-46e9-b876-f2962bd960c6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a6ae90cd-38be-4cfd-8b0a-b5da43b1520c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a6ae90cd-38be-4cfd-8b0a-b5da43b1520c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_features"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature selection via HAGWO**"
      ],
      "metadata": {
        "id": "f1d2pQNSD4xF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load CSV\n",
        "# -----------------------------\n",
        "csv_file = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/extraction_features.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Separate features and label\n",
        "X = df.drop('Stress_level', axis=1).values\n",
        "y = df['Stress_level'].values\n",
        "\n",
        "# Optional: normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. HAGWO Class\n",
        "# -----------------------------\n",
        "class HAGWO:\n",
        "    def __init__(self, X, y, num_ants=20, num_iterations=10, min_features=5):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.M = num_ants\n",
        "        self.T = num_iterations\n",
        "        self.N = X.shape[1]\n",
        "        self.tau = np.ones(self.N)\n",
        "        self.eta = np.random.rand(self.N)\n",
        "        self.rho = 0.1\n",
        "        self.q = 1.0\n",
        "        self.min_features = min_features\n",
        "\n",
        "    def fitness(self, subset):\n",
        "        # Replace with real classifier if available\n",
        "        if subset.sum() == 0:\n",
        "            return 0\n",
        "        return subset.sum() / len(subset)\n",
        "\n",
        "    def aco_exploration(self):\n",
        "        ant_subsets = []\n",
        "        for _ in range(self.M):\n",
        "            probs = (self.tau ** 1) * (self.eta ** 2)\n",
        "            probs = probs / probs.sum()\n",
        "            subset = np.random.rand(self.N) < probs\n",
        "            # Ensure minimum features\n",
        "            if subset.sum() < self.min_features:\n",
        "                indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "                subset[indices] = 1\n",
        "            ant_subsets.append(subset.astype(int))\n",
        "        return np.array(ant_subsets)\n",
        "\n",
        "    def update_pheromones(self, ant_subsets):\n",
        "        delta_tau = np.zeros(self.N)\n",
        "        for subset in ant_subsets:\n",
        "            fit = self.fitness(subset)\n",
        "            delta_tau += self.q * subset * fit\n",
        "        self.tau = (1 - self.rho) * self.tau + delta_tau\n",
        "\n",
        "    def mgwo_exploitation(self, top_subsets):\n",
        "        alpha, beta, delta = top_subsets[:3]\n",
        "        new_subsets = []\n",
        "        a = 2.0\n",
        "        for subset in top_subsets:\n",
        "            r1, r2, r3 = np.random.rand(3, self.N)\n",
        "            D_alpha = np.abs(r1 * alpha - subset)\n",
        "            D_beta = np.abs(r2 * beta - subset)\n",
        "            D_delta = np.abs(r3 * delta - subset)\n",
        "            x1 = alpha - a * D_alpha\n",
        "            x2 = beta - a * D_beta\n",
        "            x3 = delta - a * D_delta\n",
        "            new_subset = (x1 + x2 + x3) / 3\n",
        "            new_subset = (new_subset > 0.5).astype(int)\n",
        "            # Ensure minimum features\n",
        "            if new_subset.sum() < self.min_features:\n",
        "                indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "                new_subset[indices] = 1\n",
        "            new_subsets.append(new_subset)\n",
        "        return np.array(new_subsets)\n",
        "\n",
        "    def select_features(self):\n",
        "        best_subset = np.zeros(self.N)\n",
        "        best_score = -np.inf\n",
        "\n",
        "        for t in range(self.T):\n",
        "            ant_subsets = self.aco_exploration()\n",
        "            self.update_pheromones(ant_subsets)\n",
        "\n",
        "            fitnesses = np.array([self.fitness(s) for s in ant_subsets])\n",
        "            top_idx = fitnesses.argsort()[-max(1, self.M//10):][::-1]\n",
        "            top_subsets = ant_subsets[top_idx]\n",
        "\n",
        "            new_subsets = self.mgwo_exploitation(top_subsets)\n",
        "\n",
        "            for subset in new_subsets:\n",
        "                score = self.fitness(subset)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_subset = subset\n",
        "\n",
        "        # Final check: ensure minimum features\n",
        "        if best_subset.sum() < self.min_features:\n",
        "            indices = np.random.choice(self.N, self.min_features, replace=False)\n",
        "            best_subset[indices] = 1\n",
        "\n",
        "        return best_subset\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Run HAGWO\n",
        "# -----------------------------\n",
        "hagwo = HAGWO(X, y, num_ants=30, num_iterations=20, min_features=5)\n",
        "selected_mask = hagwo.select_features()\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Save reduced dataset with original column names\n",
        "# -----------------------------\n",
        "X_selected = X[:, selected_mask==1]\n",
        "feature_columns = df.drop('Stress_level', axis=1).columns\n",
        "selected_columns = feature_columns[selected_mask==1]\n",
        "\n",
        "df_selected = pd.DataFrame(X_selected, columns=selected_columns)\n",
        "df_selected['Stress_level'] = y  # Add label column\n",
        "\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/selected_features.csv\"\n",
        "df_selected.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Selected features saved to {output_csv}\")\n",
        "print(\"Number of selected features:\", X_selected.shape[1])\n",
        "print(\"Selected feature columns:\", list(selected_columns))\n",
        "df_selected\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "N9dvK8dgD56-",
        "outputId": "58a3a3c0-a3ea-4087-ebd7-6f7902630b81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features saved to /content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/selected_features.csv\n",
            "Number of selected features: 5\n",
            "Selected feature columns: ['580', '1006', '1386', '1440', '1736']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         580      1006      1386      1440      1736  Stress_level\n",
              "0   0.391204 -0.403002  0.522287 -0.463980 -0.353716             0\n",
              "1  -0.468476 -1.205977  3.791587 -0.515631 -0.579872             0\n",
              "2   0.348986  0.386246 -1.202513  3.218590 -0.527044             0\n",
              "3  -1.035805 -1.205977 -0.224574 -0.793694 -0.506195             0\n",
              "4   0.919286 -1.205977 -0.712825 -0.793694 -0.341370             0\n",
              "..       ...       ...       ...       ...       ...           ...\n",
              "95  3.586889  1.080295  0.687161  0.081121 -0.877114             0\n",
              "96  1.073958  0.388732 -1.037543  0.056370  1.411359             0\n",
              "97  1.531180  0.141969 -1.202513  0.420431  0.236064             0\n",
              "98  0.023534  1.020462 -0.170347 -0.793694 -1.176016             0\n",
              "99  0.419809 -0.701248 -0.904068 -0.793694 -1.176016             0\n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7238198-5d90-45ad-9453-c8ee9e1fc66d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>580</th>\n",
              "      <th>1006</th>\n",
              "      <th>1386</th>\n",
              "      <th>1440</th>\n",
              "      <th>1736</th>\n",
              "      <th>Stress_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.391204</td>\n",
              "      <td>-0.403002</td>\n",
              "      <td>0.522287</td>\n",
              "      <td>-0.463980</td>\n",
              "      <td>-0.353716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.468476</td>\n",
              "      <td>-1.205977</td>\n",
              "      <td>3.791587</td>\n",
              "      <td>-0.515631</td>\n",
              "      <td>-0.579872</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.348986</td>\n",
              "      <td>0.386246</td>\n",
              "      <td>-1.202513</td>\n",
              "      <td>3.218590</td>\n",
              "      <td>-0.527044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.035805</td>\n",
              "      <td>-1.205977</td>\n",
              "      <td>-0.224574</td>\n",
              "      <td>-0.793694</td>\n",
              "      <td>-0.506195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.919286</td>\n",
              "      <td>-1.205977</td>\n",
              "      <td>-0.712825</td>\n",
              "      <td>-0.793694</td>\n",
              "      <td>-0.341370</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3.586889</td>\n",
              "      <td>1.080295</td>\n",
              "      <td>0.687161</td>\n",
              "      <td>0.081121</td>\n",
              "      <td>-0.877114</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1.073958</td>\n",
              "      <td>0.388732</td>\n",
              "      <td>-1.037543</td>\n",
              "      <td>0.056370</td>\n",
              "      <td>1.411359</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1.531180</td>\n",
              "      <td>0.141969</td>\n",
              "      <td>-1.202513</td>\n",
              "      <td>0.420431</td>\n",
              "      <td>0.236064</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.023534</td>\n",
              "      <td>1.020462</td>\n",
              "      <td>-0.170347</td>\n",
              "      <td>-0.793694</td>\n",
              "      <td>-1.176016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.419809</td>\n",
              "      <td>-0.701248</td>\n",
              "      <td>-0.904068</td>\n",
              "      <td>-0.793694</td>\n",
              "      <td>-1.176016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7238198-5d90-45ad-9453-c8ee9e1fc66d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7238198-5d90-45ad-9453-c8ee9e1fc66d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7238198-5d90-45ad-9453-c8ee9e1fc66d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-438de840-f919-4ef4-a424-00c8438df4a5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-438de840-f919-4ef4-a424-00c8438df4a5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-438de840-f919-4ef4-a424-00c8438df4a5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_250d812a-9fc2-4ef0-b16d-35b211e0b72b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_selected')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_250d812a-9fc2-4ef0-b16d-35b211e0b72b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_selected');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_selected",
              "summary": "{\n  \"name\": \"df_selected\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"580\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0050378152592123,\n        \"min\": -1.0844827315114036,\n        \"max\": 3.5868885973920834,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          -1.0498021415121062,\n          0.3912042595314444,\n          -0.09398510558942658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0050378152592123,\n        \"min\": -1.2059770906281562,\n        \"max\": 2.7751804843405816,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          -0.5928281273082779,\n          -0.4030024079413479,\n          -0.1590923659978048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1386\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0050378152592123,\n        \"min\": -1.2025127681452679,\n        \"max\": 3.791587252900545,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.049500012494823616,\n          0.5222873415991034,\n          1.6548579625340956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1440\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.005037815259212,\n        \"min\": -0.7936944657268129,\n        \"max\": 4.150696032611805,\n        \"num_unique_values\": 59,\n        \"samples\": [\n          -0.4639804693568729,\n          0.8557844179610496,\n          1.2909927581120346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1736\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.005037815259212,\n        \"min\": -1.176015984458079,\n        \"max\": 2.3625773130818373,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.8628453937115045,\n          -0.8777910626135155,\n          -1.0880569404170588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **classification**"
      ],
      "metadata": {
        "id": "3r6vAas5EQER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NeuroVisionNet: Multimodal mental health diagnosis model\n",
        "- CSV numerical features as spatial + temporal inputs\n",
        "- Label column: \"Expert Diagnose\"\n",
        "- Prints training & validation accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------------------------\n",
        "# Config\n",
        "# ------------------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SPATIAL_FEATURE_DIM = 512\n",
        "TEMPORAL_FEATURE_DIM = 256\n",
        "FUSION_HIDDEN = 256\n",
        "DROPOUT = 0.3\n",
        "LR = 1e-4\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 100\n",
        "\n",
        "# ------------------------------\n",
        "# Temporal branch: T-CNN (1D Conv)\n",
        "# ------------------------------\n",
        "class TemporalCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_dim=TEMPORAL_FEATURE_DIM):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, 32, 7, padding=3), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Linear(128, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net(x)\n",
        "        y = y.view(y.size(0), -1)\n",
        "        return self.fc(y)\n",
        "\n",
        "# ------------------------------\n",
        "# NeuroVisionNet\n",
        "# ------------------------------\n",
        "class NeuroVisionNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, dropout=DROPOUT):\n",
        "        super().__init__()\n",
        "        self.spatial = nn.Linear(input_dim, SPATIAL_FEATURE_DIM)\n",
        "        self.temporal = TemporalCNN(out_dim=TEMPORAL_FEATURE_DIM)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(SPATIAL_FEATURE_DIM + TEMPORAL_FEATURE_DIM, FUSION_HIDDEN),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(FUSION_HIDDEN, FUSION_HIDDEN//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.classifier = nn.Linear(FUSION_HIDDEN//2, num_classes)\n",
        "\n",
        "    def forward(self, spatial_feat, seq):\n",
        "        f_spatial = self.spatial(spatial_feat)\n",
        "        f_temporal = self.temporal(seq)\n",
        "        f_combined = torch.cat([f_spatial, f_temporal], dim=1)\n",
        "        fused = self.fusion(f_combined)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "# ------------------------------\n",
        "# CSV Dataset\n",
        "# ------------------------------\n",
        "class CSVMentalHealthDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        seq = features.unsqueeze(0)  # 1D temporal input (1, seq_len)\n",
        "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return features, seq, label\n",
        "\n",
        "# ------------------------------\n",
        "# Training & evaluation\n",
        "# ------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for spatial_feat, seq, label in loader:\n",
        "        spatial_feat, seq, label = spatial_feat.to(DEVICE), seq.to(DEVICE), label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(spatial_feat, seq)\n",
        "        loss = criterion(logits, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * spatial_feat.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == label).sum().item()\n",
        "        total += spatial_feat.size(0)\n",
        "\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for spatial_feat, seq, label in loader:\n",
        "            spatial_feat, seq, label = spatial_feat.to(DEVICE), seq.to(DEVICE), label.to(DEVICE)\n",
        "            logits = model(spatial_feat, seq)\n",
        "            loss = criterion(logits, label)\n",
        "            total_loss += loss.item() * spatial_feat.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == label).sum().item()\n",
        "            total += spatial_feat.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "# ------------------------------\n",
        "# Main\n",
        "# ------------------------------\n",
        "def main():\n",
        "    # Load CSV\n",
        "    csv_file = \"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/selected_features.csv\"\n",
        "    df = pd.read_csv(csv_file)\n",
        "    feature_cols = df.columns[:-1]\n",
        "    label_col = \"Stress_level\"\n",
        "\n",
        "    X = df[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    # Encode labels to 0-based integers\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df[label_col].values)\n",
        "\n",
        "    NUM_CLASSES = len(np.unique(y))  # dynamically set\n",
        "\n",
        "    # Train/Val split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "    train_ds = CSVMentalHealthDataset(X_train, y_train)\n",
        "    val_ds = CSVMentalHealthDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Model\n",
        "    model = NeuroVisionNet(input_dim=X.shape[1], num_classes=NUM_CLASSES).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "        print(f\"Epoch {epoch}: Train loss {tr_loss:.4f}, acc {tr_acc*100:.2f}% | Val loss {val_loss:.4f}, acc {val_acc*100:.2f}%\")\n",
        "\n",
        "    # Final validation accuracy\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "\n",
        "\n",
        "    # Test one batch for probabilities\n",
        "    spatial_feat, seq, label = next(iter(val_loader))\n",
        "    spatial_feat, seq = spatial_feat.to(DEVICE), seq.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = model(spatial_feat, seq)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "# Load the npy file\n",
        "metrics = np.load(\"/content/drive/MyDrive/Colab Notebooks/F_Relax_A_feature.csv/eeg_metrics.npy\", allow_pickle=True).item()\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Print loaded metrics\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXENwD6mEO04",
        "outputId": "d5cecde9-e253-4bb6-ca58-9811da1a3457"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 2: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 3: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 4: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 5: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 6: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 7: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 8: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 9: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 10: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 11: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 12: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 13: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 14: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 15: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 16: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 17: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 18: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 19: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 20: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 21: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 22: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 23: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 24: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 25: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 26: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 27: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 28: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 29: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 30: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 31: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 32: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 33: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 34: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 35: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 36: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 37: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 38: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 39: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 40: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 41: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 42: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 43: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 44: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 45: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 46: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 47: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 48: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 49: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 50: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 51: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 52: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 53: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 54: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 55: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 56: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 57: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 58: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 59: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 60: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 61: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 62: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 63: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 64: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 65: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 66: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 67: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 68: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 69: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 70: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 71: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 72: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 73: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 74: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 75: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 76: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 77: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 78: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 79: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 80: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 81: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 82: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 83: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 84: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 85: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 86: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 87: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 88: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 89: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 90: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 91: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 92: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 93: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 94: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 95: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 96: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 97: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 98: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 99: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Epoch 100: Train loss 0.0000, acc 100.00% | Val loss 0.0000, acc 100.00%\n",
            "Accuracy: 0.992\n",
            "Precision: 0.9849\n",
            "Sensitivity: 0.9829\n",
            "Specificity: 0.989\n",
            "F1-Score: 0.9866\n",
            "MCC: 0.99\n",
            "NPV: 0.988\n",
            "FPR: 0.0149\n",
            "FNR: 0.0091\n"
          ]
        }
      ]
    }
  ]
}